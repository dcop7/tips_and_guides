# Disclaimer
This repository contains information collected from various online sources and/or generated by AI assistants. The content provided here is for informational purposes only and is intended to serve as a general reference on various topics.

# PostgreSQL Query Performance Analysis: Using EXPLAIN and EXPLAIN ANALYZE

## Table of Contents
- [Introduction](#introduction)
- [Basic EXPLAIN Syntax](#basic-explain-syntax)
- [EXPLAIN vs EXPLAIN ANALYZE](#explain-vs-explain-analyze)
- [Understanding Query Plans](#understanding-query-plans)
  - [Node Types](#node-types)
  - [Cost Estimation](#cost-estimation)
  - [Key Performance Metrics](#key-performance-metrics)
- [Common EXPLAIN Options](#common-explain-options)
- [Reading EXPLAIN Output Top-to-Bottom](#reading-explain-output-top-to-bottom)
- [Identifying Common Performance Issues](#identifying-common-performance-issues)
- [Practical Examples](#practical-examples)
  - [Example 1: Sequential Scan vs Index Scan](#example-1-sequential-scan-vs-index-scan)
  - [Example 2: Join Operations](#example-2-join-operations)
  - [Example 3: Subquery Performance](#example-3-subquery-performance)
  - [Example 4: Aggregation Queries](#example-4-aggregation-queries)
- [EXPLAIN Formats](#explain-formats)
- [Best Practices](#best-practices)
- [Troubleshooting Common Issues](#troubleshooting-common-issues)

## Introduction

PostgreSQL's `EXPLAIN` command is a powerful tool that shows how the query planner intends to execute a query. It provides insight into how tables are scanned, joined, and what indexes are used. When combined with the `ANALYZE` option, it executes the query and provides actual runtime statistics, making it an invaluable tool for performance tuning.

This guide covers how to use `EXPLAIN` and `EXPLAIN ANALYZE` effectively to diagnose and solve performance issues in your PostgreSQL database.

## Basic EXPLAIN Syntax

The basic syntax for using EXPLAIN is:

```sql
EXPLAIN [options] query;
```

Where `query` is any SELECT, INSERT, UPDATE, DELETE, VALUES, EXECUTE, DECLARE, CREATE TABLE AS, or CREATE MATERIALIZED VIEW AS statement.

For example:

```sql
EXPLAIN SELECT * FROM users WHERE email = 'john@example.com';
```

## EXPLAIN vs EXPLAIN ANALYZE

There are two primary ways to use the EXPLAIN command:

1. **EXPLAIN**: Shows the execution plan that the query planner generates without actually executing the query. This is useful for a preliminary analysis without affecting the database.

```sql
EXPLAIN SELECT * FROM orders WHERE order_date > '2023-01-01';
```

2. **EXPLAIN ANALYZE**: Both generates the execution plan AND executes the query, providing real timing and row statistics. This gives you actual performance metrics but will modify data if used with INSERT, UPDATE, or DELETE statements.

```sql
EXPLAIN ANALYZE SELECT * FROM orders WHERE order_date > '2023-01-01';
```

> ⚠️ **Warning**: Be careful using `EXPLAIN ANALYZE` with data manipulation statements (INSERT, UPDATE, DELETE) as they will actually execute and change your data!

## Understanding Query Plans

Query plans are organized as a tree of execution nodes. Each node represents an operation, and nodes are executed from the innermost (bottom) to the outermost (top).

### Node Types

Common node types you'll encounter include:

- **Scan nodes**: Methods for reading data from tables
  - `Seq Scan`: Reads all rows from a table sequentially
  - `Index Scan`: Uses an index to find specific rows
  - `Index Only Scan`: Retrieves data directly from the index without accessing the table
  - `Bitmap Heap Scan`: Two-phase scan that first collects row locations and then fetches them

- **Join nodes**: Methods for combining tables
  - `Nested Loop`: For each row in the outer table, scans the inner table
  - `Hash Join`: Builds a hash table from the smaller relation, then probes it with the larger relation
  - `Merge Join`: Merges two pre-sorted inputs

- **Other nodes**:
  - `Sort`: Sorts rows
  - `Aggregate`: Performs GROUP BY operations
  - `Limit`: Implements LIMIT clause
  - `Hash`: Creates an in-memory hash table
  - `Materialize`: Stores results in memory for repeated access

### Cost Estimation

In EXPLAIN output, you'll see cost values like `cost=0.42..1.23`. These values represent:

- The startup cost (before the first row is returned): `0.42` in the example
- The total cost (to return all rows): `1.23` in the example

Costs are in arbitrary units determined by planner cost parameters and represent estimated disk page fetches.

### Key Performance Metrics

When using `EXPLAIN ANALYZE`, look for:

- **Actual time**: Shows execution time in milliseconds (e.g., `actual time=0.028..0.029 ms`)
- **Rows**: Estimated vs actual number of rows processed
- **Loops**: Number of times this node was executed
- **Buffers**: When using `BUFFERS` option, shows shared, local, and temp buffers used

## Common EXPLAIN Options

PostgreSQL's EXPLAIN command supports several options to provide additional details:

```sql
EXPLAIN (ANALYZE, BUFFERS, FORMAT JSON) SELECT * FROM users JOIN orders ON users.id = orders.user_id;
```

Available options include:

| Option | Description |
|--------|-------------|
| ANALYZE | Executes the query and shows actual run times and row counts |
| VERBOSE | Shows additional information like column names, table schemas, etc. |
| COSTS | Shows estimated startup and total costs (on by default) |
| BUFFERS | Shows buffer usage statistics (shared, local, temp buffers) |
| TIMING | Include actual timing information for each node (on by default with ANALYZE) |
| FORMAT | Output format: TEXT (default), XML, JSON, or YAML |
| SETTINGS | Include information about non-default configuration parameters |
| WAL | Include WAL (Write-Ahead Log) record generation statistics |

## Reading EXPLAIN Output Top-to-Bottom

EXPLAIN output should be read from innermost to outermost operations, or bottom-to-top:

1. Start at the innermost indented operations (at the bottom)
2. Follow the flow upward to see how data is processed
3. Pay attention to the estimated/actual rows at each step
4. Notice where large discrepancies exist between estimated and actual rows

## Identifying Common Performance Issues

Using EXPLAIN, you can identify several common performance issues:

1. **Sequential scans on large tables**: Look for `Seq Scan` on tables that should use indexes
2. **Missing indexes**: High-cost operations where an index could help
3. **Inefficient joins**: Nested loop joins with large tables
4. **Inaccurate statistics**: Large discrepancies between estimated and actual row counts
5. **Suboptimal join order**: When the planner chooses a bad order to join tables
6. **Excessive sorting**: When sorts could be avoided with proper indexes
7. **High buffer usage**: Operations reading many disk pages

## Practical Examples

### Example 1: Sequential Scan vs Index Scan

Let's compare a query with and without proper indexing:

```sql
-- First, analyze a table without proper indexing
EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'john@example.com';
```

Output:
```
                                  QUERY PLAN
-------------------------------------------------------------------------------
Seq Scan on users  (cost=0.00..155.00 rows=1 width=90) (actual time=0.436..7.836 ms)
  Filter: ((email)::text = 'john@example.com'::text)
  Rows Removed by Filter: 9999
Planning Time: 0.153 ms
Execution Time: 7.871 ms
```

Now let's create an index and try again:

```sql
CREATE INDEX idx_users_email ON users(email);

EXPLAIN ANALYZE SELECT * FROM users WHERE email = 'john@example.com';
```

Output:
```
                                  QUERY PLAN
-------------------------------------------------------------------------------
Index Scan using idx_users_email on users  (cost=0.29..8.31 rows=1 width=90) (actual time=0.037..0.039 ms)
  Index Cond: ((email)::text = 'john@example.com'::text)
Planning Time: 0.123 ms
Execution Time: 0.068 ms
```

The index scan is significantly faster because it directly locates the matching row instead of scanning the entire table.

### Example 2: Join Operations

Let's analyze a query that joins two tables:

```sql
EXPLAIN ANALYZE
SELECT u.name, o.order_total 
FROM users u 
JOIN orders o ON u.id = o.user_id
WHERE o.order_date > '2023-01-01';
```

Output:
```
                                    QUERY PLAN
----------------------------------------------------------------------------------
Hash Join  (cost=15.38..40.97 rows=500 width=40) (actual time=0.397..1.471 ms)
  Hash Cond: (o.user_id = u.id)
  ->  Seq Scan on orders o  (cost=0.00..22.00 rows=500 width=16) (actual time=0.012..0.281 ms)
        Filter: (order_date > '2023-01-01'::date)
        Rows Removed by Filter: 500
  ->  Hash  (cost=10.50..10.50 rows=1000 width=36) (actual time=0.359..0.360 ms)
        Buckets: 1024  Batches: 1  Memory Usage: 58kB
        ->  Seq Scan on users u  (cost=0.00..10.50 rows=1000 width=36) (actual time=0.011..0.169 ms)
Planning Time: 0.265 ms
Execution Time: 1.516 ms
```

In this example:
1. A sequential scan is performed on `users` to build a hash table
2. A sequential scan is performed on `orders` with a filter
3. Each order row's `user_id` is used to probe the hash table

If we wanted to optimize this, we might add indexes on `orders.order_date` and `orders.user_id`.

### Example 3: Subquery Performance

Let's compare a subquery against a join:

```sql
-- Using a subquery
EXPLAIN ANALYZE
SELECT name FROM users 
WHERE id IN (SELECT user_id FROM orders WHERE order_total > 1000);

-- Using a join
EXPLAIN ANALYZE
SELECT DISTINCT u.name FROM users u 
JOIN orders o ON u.id = o.user_id 
WHERE o.order_total > 1000;
```

Comparing the two plans allows you to see which approach is more efficient for your specific data.

### Example 4: Aggregation Queries

Let's analyze a query with aggregation:

```sql
EXPLAIN ANALYZE
SELECT 
    product_category, 
    SUM(order_total) as total_sales
FROM orders
GROUP BY product_category
ORDER BY total_sales DESC;
```

Output:
```
                                     QUERY PLAN
-----------------------------------------------------------------------------------
Sort  (cost=69.86..70.11 rows=100 width=40) (actual time=0.637..0.641 ms)
  Sort Key: (sum(order_total)) DESC
  Sort Method: quicksort  Memory: 25kB
  ->  HashAggregate  (cost=65.50..66.75 rows=100 width=40) (actual time=0.604..0.615 ms)
        Group Key: product_category
        Batches: 1  Memory Usage: 40kB
        ->  Seq Scan on orders  (cost=0.00..48.00 rows=1000 width=16) (actual time=0.015..0.263 ms)
Planning Time: 0.134 ms
Execution Time: 0.678 ms
```

This plan shows:
1. A sequential scan on the orders table
2. A hash aggregation for the GROUP BY
3. A sort for the ORDER BY

## EXPLAIN Formats

EXPLAIN outputs can be formatted in different ways for easier analysis or integration with tools:

1. **TEXT format** (default):
```sql
EXPLAIN SELECT * FROM users;
```

2. **JSON format**:
```sql
EXPLAIN (FORMAT JSON) SELECT * FROM users;
```

3. **XML format**:
```sql
EXPLAIN (FORMAT XML) SELECT * FROM users;
```

4. **YAML format**:
```sql
EXPLAIN (FORMAT YAML) SELECT * FROM users;
```

The JSON, XML, and YAML formats are particularly useful for programmatic analysis of query plans.

## Best Practices

1. **Compare alternatives**: Use EXPLAIN to compare different query approaches

2. **Watch for big discrepancies**: Look for large differences between estimated and actual row counts, which may indicate outdated statistics

3. **Run ANALYZE regularly**: Keep statistics up-to-date
   ```sql
   ANALYZE users;
   ```

4. **Use BUFFERS option**: To see I/O behavior
   ```sql
   EXPLAIN (ANALYZE, BUFFERS) SELECT * FROM large_table;
   ```

5. **Real production data**: Test with realistic data volumes and distributions

6. **Check for sequential scans**: On large tables, these usually indicate missing indexes

7. **Watch memory usage**: Particularly for operations like Hash Join and Sort

## Troubleshooting Common Issues

1. **Incorrect row estimates**: Run `ANALYZE` on the tables to update statistics

2. **Bad join methods**: Consider increasing `work_mem` if hash joins are spilling to disk
   ```sql
   SET work_mem = '64MB';
   ```

3. **Inefficient execution plans**: Try disabling certain join methods to test alternatives
   ```sql
   SET enable_nestloop = off;
   ```

4. **Slow parallel queries**: Check `max_parallel_workers_per_gather` and make sure parallel plans are being chosen
   ```sql
   SHOW max_parallel_workers_per_gather;
   ```

5. **Force index usage**: Sometimes you need to temporarily force the planner to use an index
   ```sql
   SET enable_seqscan = off;
   ```

Remember that while EXPLAIN is a powerful tool, it's not the only factor in query optimization. Consider also examining your schema design, hardware resources, and PostgreSQL configuration parameters for a comprehensive performance tuning approach.
